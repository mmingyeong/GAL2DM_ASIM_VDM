{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8b568f",
   "metadata": {},
   "source": [
    "### 4. Model Complexity & Practical Usability (모델 복잡도 및 실용성)\n",
    "\n",
    "이 표는 각 모델이 **얼마나 계산적으로 무거운지**, 그리고 실제 사용할 때 **연산/메모리 비용**이 어느 정도인지 비교합니다.\n",
    "\n",
    "| Metric | 의미 (Korean 설명) |\n",
    "|-------|----------------|\n",
    "| **Params (#)** | 학습 가능한 파라미터 총 개수. 모델 표현력 규모를 반영하나, 너무 크면 과적합 및 메모리 비용 증가 가능. |\n",
    "| **FLOPs** | 단일 추론(Forward pass) 동안 수행되는 부동소수점 연산 수. 연산 복잡도의 직접적인 척도. |\n",
    "| **Inference Memory (MB)** | 입력 1개를 추론할 때 GPU 메모리가 어느 정도 사용되는지. |\n",
    "| **Latency per Inference (s)** | 입력 하나를 처리하는 데 걸리는 시간. 실시간 처리 가능성 및 배치 사이즈 결정에 영향. |\n",
    "\n",
    "#### 해석 관점\n",
    "- **ViT** 계열은 일반적으로 **파라미터 수는 크지만 FLOPs 효율이 좋아** 추론 속도는 빠른 편.\n",
    "- **UNet3D (V-NET)** 는 **입체 convolution 핵심 구조로 인해 메모리 사용량이 크고 추론 시간이 상대적으로 길 수 있음.**\n",
    "- **Base Model** 은 구조가 단순하므로 일반적으로 가장 가볍지만 성능 한계가 존재.\n",
    "\n",
    "즉,\n",
    "> 이 표는 “**정확도 vs 계산비용**” 트레이드오프를 정량적으로 보여주며,  \n",
    "> 실제 운용 환경에서 어떤 모델을 선택해야 하는지를 결정하는 핵심 기준이 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105bbea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 11:43:21.417452: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-27 11:43:32.568488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# <<< 이 셀을 노트북 \"맨 위\"에서 실행하세요 >>>\n",
    "import os\n",
    "# TF가 GPU를 전혀 보지 못하도록 비활성화 (CPU 강제)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "# GPU가 안 보이므로 굳이 메모리 그로스 설정은 불필요\n",
    "\n",
    "# PyTorch는 별도 환경에서 GPU 사용 (CUDA_VISIBLE_DEVICES가 빈 문자열이면 CPU만 보임)\n",
    "# -> Torch쪽에서는 다시 원하는 GPU를 지정해서 사용하세요 (SLURM 스크립트 등에서 지정)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2328060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Complexity Summary (Including VDM) ===\n",
      "\n",
      "                       Model Params (#)    FLOPs     MACs Inference Memory (MB) Latency per Inference (s)\n",
      "              V-NET (UNet3D)   28.824 M 121.235G  60.617G                937 MB                  30.64 ms\n",
      "        ViT (3D Transformer)   23.502 M   2.282T   1.141T              2,994 MB                 119.53 ms\n",
      "cGAN (Pix2PixCC3D-Generator)   27.808 M 953.571G 476.785G              1,100 MB                 211.51 ms\n",
      "             Base Model (TF)  461.007 M   1.840T      NaN              6,002 MB                 248.64 ms\n",
      "        VDM (CUNet backbone)   38.993 M   2.777T   1.389T                   NaN                2509.18 ms\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from thop import profile\n",
    "\n",
    "from src.model import VDM, CUNet\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. VDM + CUNet 생성\n",
    "# ============================================================\n",
    "def build_vdm_model(spatial_shape=(128, 128, 128), s_cond_ch=2):\n",
    "    D, H, W = spatial_shape\n",
    "    score_shape = (1, D, H, W)\n",
    "\n",
    "    score_model = CUNet(\n",
    "        shape=score_shape,\n",
    "        out_channels=1,\n",
    "        s_conditioning_channels=s_cond_ch,\n",
    "        v_conditioning_dims=[],\n",
    "        v_conditioning_type=\"common_zerolinear\",\n",
    "        v_embedding_dim=64,\n",
    "        v_augment=False,\n",
    "        v_embed_no_s_gelu=False,\n",
    "        t_conditioning=True,\n",
    "        t_embedding_dim=64,\n",
    "        init_scale=0.02,\n",
    "        num_res_blocks=1,\n",
    "        norm_groups=8,\n",
    "        mid_attn=False,\n",
    "        n_attention_heads=4,\n",
    "        dropout_prob=0.1,\n",
    "        conv_padding_mode=\"zeros\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    vdm = VDM(\n",
    "        score_model=score_model,\n",
    "        noise_schedule=\"fixed_linear\",\n",
    "        gamma_min=-13.3,\n",
    "        gamma_max=5.0,\n",
    "        antithetic_time_sampling=True,\n",
    "        data_noise=1e-3,\n",
    "    )\n",
    "    return vdm\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Complexity 측정\n",
    "# ============================================================\n",
    "def measure_vdm_complexity():\n",
    "    \"\"\"\n",
    "    - FLOPs/MACs: score_model(CUNet) 한 번 forward 기준\n",
    "    - Memory/Latency: VDM.get_loss 한 번 호출 기준\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")  # GPU OOM 피하려고 CPU 기준으로 측정\n",
    "\n",
    "    model = build_vdm_model(spatial_shape=(128, 128, 128), s_cond_ch=2).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    B = 1\n",
    "    zt = torch.randn(B, 1, 128, 128, 128, device=device)\n",
    "    s_cond = torch.randn(B, 2, 128, 128, 128, device=device)\n",
    "    y = torch.randn(B, 1, 128, 128, 128, device=device)\n",
    "    t = torch.zeros(B, device=device)  # dummy t\n",
    "\n",
    "    # ---------------- FLOPs / MACs (score_model) ----------------\n",
    "    class ScoreWrapper(nn.Module):\n",
    "        def __init__(self, score_model, t, s_cond):\n",
    "            super().__init__()\n",
    "            self.score_model = score_model\n",
    "            self.register_buffer(\"t\", t)\n",
    "            self.register_buffer(\"s_cond\", s_cond)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.score_model(x, t=self.t, s_conditioning=self.s_cond)\n",
    "\n",
    "    wrapper = ScoreWrapper(model.score_model, t, s_cond).to(device)\n",
    "    wrapper.eval()\n",
    "\n",
    "    macs, params_thop = profile(wrapper, inputs=(zt,), verbose=False)\n",
    "    flops = macs * 2  # 관례적으로 FLOPs ≈ 2 * MACs\n",
    "\n",
    "    # ---------------- 파라미터 수 (VDM 전체) ----------------\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    # ---------------- 메모리 (GPU 아니면 NaN) ----------------\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = model.get_loss(x=y, s_conditioning=s_cond, reduction=\"mean\")\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        peak_mem = torch.cuda.max_memory_allocated(device) / (1024 ** 2)\n",
    "    else:\n",
    "        peak_mem = float(\"nan\")\n",
    "\n",
    "    # ---------------- Latency (get_loss) ----------------\n",
    "    runs = 5\n",
    "    with torch.no_grad():\n",
    "        for _ in range(2):  # warm-up\n",
    "            _ = model.get_loss(x=y, s_conditioning=s_cond, reduction=\"mean\")\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize(device)\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in range(runs):\n",
    "            _ = model.get_loss(x=y, s_conditioning=s_cond, reduction=\"mean\")\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize(device)\n",
    "        end = time.time()\n",
    "\n",
    "    latency = (end - start) / runs\n",
    "\n",
    "    return {\n",
    "        \"Model\": \"VDM (CUNet backbone)\",\n",
    "        \"Params (#)\": float(params),\n",
    "        \"FLOPs\": float(flops),\n",
    "        \"MACs\": float(macs),\n",
    "        \"Inference Memory (MB)\": float(peak_mem),\n",
    "        \"Latency per Inference (s)\": float(latency),\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. 기존 CSV + VDM 행 추가 + 포맷 통일\n",
    "# ============================================================\n",
    "csv_path = \"/home/mingyeong/GAL2DM_ASIM_VNET/eval/model_complexity_summary_all_with_cgan.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "vdm_row = measure_vdm_complexity()\n",
    "df = pd.concat([df, pd.DataFrame([vdm_row])], ignore_index=True)\n",
    "\n",
    "# ----- 포맷 함수들 -----\n",
    "def fmt_params(n):\n",
    "    if isinstance(n, str): return n\n",
    "    if math.isnan(n): return \"NaN\"\n",
    "    if n >= 1e9:  return f\"{n/1e9:.3f} B\"\n",
    "    if n >= 1e6:  return f\"{n/1e6:.3f} M\"\n",
    "    if n >= 1e3:  return f\"{n/1e3:.3f} K\"\n",
    "    return f\"{n:.0f}\"\n",
    "\n",
    "def fmt_large_unit(x):\n",
    "    \"\"\"FLOPs, MACs 공통 포맷 (M / G / T 단위).\"\"\"\n",
    "    if isinstance(x, str): return x\n",
    "    if math.isnan(x): return \"NaN\"\n",
    "    if x >= 1e12: return f\"{x/1e12:.3f}T\"\n",
    "    if x >= 1e9:  return f\"{x/1e9:.3f}G\"\n",
    "    if x >= 1e6:  return f\"{x/1e6:.3f}M\"\n",
    "    if x >= 1e3:  return f\"{x/1e3:.3f}K\"\n",
    "    return f\"{x:.0f}\"\n",
    "\n",
    "def fmt_mem(x):\n",
    "    if isinstance(x, str): return x\n",
    "    if math.isnan(x): return \"NaN\"\n",
    "    return f\"{x:,.0f} MB\"\n",
    "\n",
    "def fmt_lat(x):\n",
    "    if isinstance(x, str): return x\n",
    "    if math.isnan(x): return \"NaN\"\n",
    "    return f\"{x*1e3:.2f} ms\"\n",
    "\n",
    "# ----- 각 컬럼에 포맷 적용 -----\n",
    "if \"Params (#)\" in df.columns:\n",
    "    df[\"Params (#)\"] = df[\"Params (#)\"].apply(fmt_params)\n",
    "if \"FLOPs\" in df.columns:\n",
    "    df[\"FLOPs\"] = df[\"FLOPs\"].apply(fmt_large_unit)\n",
    "if \"MACs\" in df.columns:\n",
    "    df[\"MACs\"] = df[\"MACs\"].apply(fmt_large_unit)\n",
    "if \"Inference Memory (MB)\" in df.columns:\n",
    "    df[\"Inference Memory (MB)\"] = df[\"Inference Memory (MB)\"].apply(fmt_mem)\n",
    "if \"Latency per Inference (s)\" in df.columns:\n",
    "    df[\"Latency per Inference (s)\"] = df[\"Latency per Inference (s)\"].apply(fmt_lat)\n",
    "\n",
    "order = [\"Model\", \"Params (#)\", \"FLOPs\", \"MACs\",\n",
    "         \"Inference Memory (MB)\", \"Latency per Inference (s)\"]\n",
    "df = df[[c for c in order if c in df.columns]]\n",
    "\n",
    "print(\"\\n=== Model Complexity Summary (Including VDM) ===\\n\")\n",
    "print(df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
