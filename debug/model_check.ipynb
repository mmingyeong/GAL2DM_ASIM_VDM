{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c363ff03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imported VDM from /home/mingyeong/GAL2DM_ASIM_VDM/src/model.py\n"
     ]
    }
   ],
   "source": [
    "# === Minimal one-cell VDM debug: load, instantiate, smoke test, summary ===\n",
    "import os, sys, importlib.util, types\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0) Paths (네가 말한 실제 경로 기준)\n",
    "# -------------------------------------------------\n",
    "PROJECT_ROOT = \"/home/mingyeong/GAL2DM_ASIM_VDM\"\n",
    "SRC_DIR      = os.path.join(PROJECT_ROOT, \"src\")\n",
    "\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.append(SRC_DIR)\n",
    "\n",
    "# 이제 src/ 아래의 model.py, model_tools.py 를\n",
    "# 그냥 top-level 모듈처럼 import 가능해짐.\n",
    "from model import VDM   # <-- 방금 만든 clean VDM 클래스\n",
    "import model_tools      # <-- 필요하면 직접 참조 가능\n",
    "\n",
    "print(\"✅ Imported VDM from\", os.path.join(SRC_DIR, \"model.py\"))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1) mltools 패키지 컨텍스트 안에서 vdm_model / model_tools 로드\n",
    "#    (vdm_model.py 내부의 `from mltools.models.model_tools import ...` 대응)\n",
    "# -------------------------------------------------\n",
    "def load_vdm_symbol(vdm_path, modeltools_path, symbol):\n",
    "    # (1) fake 패키지: mltools, mltools.models\n",
    "    if \"mltools\" not in sys.modules:\n",
    "        mltools_pkg = types.ModuleType(\"mltools\")\n",
    "        mltools_pkg.__path__ = []\n",
    "        sys.modules[\"mltools\"] = mltools_pkg\n",
    "\n",
    "    if \"mltools.models\" not in sys.modules:\n",
    "        models_pkg = types.ModuleType(\"mltools.models\")\n",
    "        models_pkg.__path__ = []\n",
    "        sys.modules[\"mltools.models\"] = models_pkg\n",
    "\n",
    "    # (2) mltools.models.model_tools 로 로드\n",
    "    if \"mltools.models.model_tools\" not in sys.modules:\n",
    "        t_spec = importlib.util.spec_from_file_location(\n",
    "            \"mltools.models.model_tools\", modeltools_path\n",
    "        )\n",
    "        t_mod = importlib.util.module_from_spec(t_spec)\n",
    "        t_mod.__package__ = \"mltools.models\"\n",
    "        sys.modules[\"mltools.models.model_tools\"] = t_mod\n",
    "        t_spec.loader.exec_module(t_mod)  # type: ignore\n",
    "\n",
    "    # (3) mltools.models.vdm_model 로 로드\n",
    "    m_spec = importlib.util.spec_from_file_location(\n",
    "        \"mltools.models.vdm_model\", vdm_path\n",
    "    )\n",
    "    m_mod = importlib.util.module_from_spec(m_spec)\n",
    "    m_mod.__package__ = \"mltools.models\"\n",
    "    sys.modules[\"mltools.models.vdm_model\"] = m_mod\n",
    "    m_spec.loader.exec_module(m_mod)  # type: ignore\n",
    "\n",
    "    return getattr(m_mod, symbol)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95afa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 2) VDM / LightVDM 클래스 로드\n",
    "# -------------------------------------------------\n",
    "VDM      = load_vdm_symbol(VDM_PATH, MODELTOOLS_PATH, \"VDM\")\n",
    "#LightVDM = load_vdm_symbol(VDM_PATH, MODELTOOLS_PATH, \"LightVDM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a66f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------\n",
    "# 3) Dummy 3D score model 정의\n",
    "#    - VDM.get_pred_noise에서 호출되는 인터페이스와 호환\n",
    "#    - forward(zt, t, **kwargs) 형태만 맞추면 됨\n",
    "# -------------------------------------------------\n",
    "class DummyScoreNet3D(nn.Module):\n",
    "    def __init__(self, in_ch: int = 1, hidden: int = 16):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, hidden, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(hidden, hidden, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(hidden, in_ch, kernel_size=3, padding=1),\n",
    "        )\n",
    "        # VDM.sample() 에서 사용하는 shape 정보\n",
    "        # (C, D, H, W) 형태로 넣어주면 됨\n",
    "        self.shape = (in_ch, 32, 32, 32)\n",
    "\n",
    "    def forward(self, zt: torch.Tensor, t: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        # 여기서는 t, kwargs는 무시하고 단순 Conv stack만 수행\n",
    "        return self.net(zt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87307337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ VDM instantiated on cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------\n",
    "# 4) VDM 인스턴스 생성\n",
    "# -------------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "score_model = DummyScoreNet3D(in_ch=1).to(device)\n",
    "vdm = VDM(\n",
    "    score_model=score_model,\n",
    "    noise_schedule=\"fixed_linear\",  # \"learned_linear\", \"learned_nn\", \"sigmoid\" 등으로 바꿔도 됨\n",
    "    gamma_min=-13.3,\n",
    "    gamma_max=5.0,\n",
    "    antithetic_time_sampling=True,\n",
    "    data_noise=1.0e-3,\n",
    ").to(device)\n",
    "vdm.eval()\n",
    "\n",
    "print(\"✅ VDM instantiated on\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876c4a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ get_loss() OK\n",
      "   elbo: 5.821023941040039\n",
      "   diffusion_loss: 13.24298095703125\n",
      "   latent_loss: 0.004859061911702156\n",
      "   reconstruction_loss: -7.426815986633301\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 5) Forward smoke test: get_loss() 체크\n",
    "#    (⚠️ inference_mode 쓰면 안 됨)\n",
    "# -------------------------------------------------\n",
    "x = torch.randn(2, 1, 32, 32, 32, device=device)\n",
    "loss, metrics = vdm.get_loss(x)   # 여기서는 grad 필요\n",
    "\n",
    "print(\"✅ get_loss() OK\")\n",
    "print(\"   elbo:\", float(metrics[\"elbo\"]))\n",
    "print(\"   diffusion_loss:\", float(metrics[\"diffusion_loss\"]))\n",
    "print(\"   latent_loss:\", float(metrics[\"latent_loss\"]))\n",
    "print(\"   reconstruction_loss:\", float(metrics[\"reconstruction_loss\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5d7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sample() OK | sample shape: (1, 1, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# Sampling 스모크 테스트\n",
    "# -------------------------------------------------\n",
    "with torch.no_grad():\n",
    "    z_samples = vdm.sample(\n",
    "        batch_size=1,\n",
    "        n_sampling_steps=8,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "    )\n",
    "print(\"✅ sample() OK | sample shape:\", tuple(z_samples.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "390580d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sample() OK | sample shape: (1, 1, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------\n",
    "# 6) Sampling smoke test: sample() 체크\n",
    "# -------------------------------------------------\n",
    "with torch.inference_mode():\n",
    "    z_samples = vdm.sample(\n",
    "        batch_size=1,\n",
    "        n_sampling_steps=8,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "    )\n",
    "print(\"✅ sample() OK | sample shape:\", tuple(z_samples.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "104441bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "DummyScoreNet3D                          [1, 1, 32, 32, 32]        [1, 1, 32, 32, 32]        --\n",
       "├─Sequential: 1-1                        [1, 1, 32, 32, 32]        [1, 1, 32, 32, 32]        --\n",
       "│    └─Conv3d: 2-1                       [1, 1, 32, 32, 32]        [1, 16, 32, 32, 32]       448\n",
       "│    └─ReLU: 2-2                         [1, 16, 32, 32, 32]       [1, 16, 32, 32, 32]       --\n",
       "│    └─Conv3d: 2-3                       [1, 16, 32, 32, 32]       [1, 16, 32, 32, 32]       6,928\n",
       "│    └─ReLU: 2-4                         [1, 16, 32, 32, 32]       [1, 16, 32, 32, 32]       --\n",
       "│    └─Conv3d: 2-5                       [1, 16, 32, 32, 32]       [1, 1, 32, 32, 32]        433\n",
       "===================================================================================================================\n",
       "Total params: 7,809\n",
       "Trainable params: 7,809\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 255.89\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 8.65\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 8.81\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# 더미 입력 (zt, t)\n",
    "xt_dummy = torch.randn(1, 1, 32, 32, 32, device=device)\n",
    "t_dummy  = torch.zeros(1, device=device)  # 그냥 0.0 time\n",
    "\n",
    "summary(\n",
    "    vdm.score_model,\n",
    "    input_data=(xt_dummy, t_dummy),   # ← 튜플로 전달\n",
    "    device=device,\n",
    "    depth=2,\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\"),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
